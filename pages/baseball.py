import streamlit as st
import feedparser
import pandas as pd
import datetime

# ------------------------------------------------------------------
# [1] í˜ì´ì§€ ì„¤ì •
# ------------------------------------------------------------------
st.set_page_config(page_title="KBO í”„ë¡œì•¼êµ¬ ë¸Œë¦¬í•‘", page_icon="âš¾", layout="centered")

st.title("âš¾ KBO í”„ë¡œì•¼êµ¬ Daily")
st.caption(f"ì˜¤ëŠ˜({datetime.date.today().strftime('%mì›” %dì¼')})ì˜ ê·¸ë¼ìš´ë“œ ì†Œì‹ì…ë‹ˆë‹¤.")

# ------------------------------------------------------------------
# [2] ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ì¤‘ë³µ ì œê±° ê¸°ëŠ¥ ì¶”ê°€)
# ------------------------------------------------------------------
def get_kbo_news():
    # ê²€ìƒ‰ì–´ ìµœì í™”: 'KBO'ë§Œ ì“°ë©´ ë„ˆë¬´ ê´‘ë²”ìœ„í•´ì„œ 'í”„ë¡œì•¼êµ¬' ì¡°í•©
    rss_url = "https://news.google.com/rss/search?q=KBO+í”„ë¡œì•¼êµ¬+news&hl=ko&gl=KR&ceid=KR:ko"
    feed = feedparser.parse(rss_url)
    
    unique_news = []
    seen_titles = set() # ì´ë¯¸ ë³¸ ì œëª©ì„ ì €ì¥í•˜ëŠ” ì§‘í•©
    
    for entry in feed.entries:
        # 1. ì œëª© ì „ì²˜ë¦¬ (ê¸°ì‚¬ ëì— ë¶™ëŠ” ì–¸ë¡ ì‚¬ ì´ë¦„ ì œê±° ë“±)
        clean_title = entry.title.split("-")[0].strip()
        
        # 2. ì¤‘ë³µ ê²€ì‚¬ (ë¹„ìŠ·í•œ ì œëª©ì´ë©´ íŒ¨ìŠ¤)
        # ì œëª© ì• 10ê¸€ìê°€ ê°™ìœ¼ë©´ ê°™ì€ ê¸°ì‚¬ë¡œ ê°„ì£¼ (ê°•ë ¥í•œ í•„í„°ë§)
        title_signature = clean_title[:10]
        
        if title_signature not in seen_titles:
            unique_news.append({
                "title": clean_title, # ê¹”ë”í•´ì§„ ì œëª© ì‚¬ìš©
                "link": entry.link,
                "published": entry.published,
                "source": entry.source.title if 'source' in entry else "ë‰´ìŠ¤"
            })
            seen_titles.add(title_signature)
            
        if len(unique_news) >= 10: # 10ê°œë§Œ ì±„ìš°ë©´ ì¤‘ë‹¨
            break
            
    return unique_news

# ------------------------------------------------------------------
# [3] í™”ë©´ êµ¬ì„±
# ------------------------------------------------------------------

# ìƒë‹¨: í€µ ë§í¬ (PC ë²„ì „ ë§í¬ë¡œ êµì²´í•˜ì—¬ ì˜¤ë¥˜ í•´ê²°)
st.info("ğŸ‘‡ ê²½ê¸° ì¼ì • ë° í•˜ì´ë¼ì´íŠ¸ëŠ” ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ í™•ì¸í•˜ì„¸ìš”!")
c1, c2, c3 = st.columns(3)

with c1:
    # ë„¤ì´ë²„ ìŠ¤í¬ì¸  PC ë²„ì „ (ëª¨ë°”ì¼ ë²„ì „ë³´ë‹¤ ì•ˆì •ì )
    st.link_button("ğŸ“… ê²½ê¸° ì¼ì •/ê²°ê³¼", "https://sports.news.naver.com/kbaseball/schedule/index.nhn", use_container_width=True)
with c2:
    st.link_button("ğŸ† ì‹¤ì‹œê°„ ìˆœìœ„", "https://sports.news.naver.com/kbaseball/record/index.nhn", use_container_width=True)
with c3:
    # í•˜ì´ë¼ì´íŠ¸ê°€ ì•ˆ ë‚˜ì˜¤ë˜ ë¬¸ì œ í•´ê²° -> ìœ íŠœë¸Œ ê²€ìƒ‰ ê²°ê³¼ë¡œ ì§í–‰ (ê°€ì¥ í™•ì‹¤í•¨)
    st.link_button("ğŸ“º í•˜ì´ë¼ì´íŠ¸ (YouTube)", "https://www.youtube.com/results?search_query=KBO+í•˜ì´ë¼ì´íŠ¸+ì˜¤ëŠ˜", use_container_width=True)

st.divider()

# ë©”ì¸: ë‰´ìŠ¤ ë¸Œë¦¬í•‘
col_head, col_btn = st.columns([4, 1])
with col_head:
    st.subheader("ğŸ“° ì˜¤ëŠ˜ì˜ í—¤ë“œë¼ì¸ (Clean Ver.)")
with col_btn:
    if st.button("ìƒˆë¡œê³ ì¹¨ ğŸ”„"):
        st.rerun()

with st.spinner("ì¤‘ë³µëœ ê¸°ì‚¬ë¥¼ ê±·ì–´ë‚´ê³  í•µì‹¬ë§Œ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
    try:
        news_items = get_kbo_news()
        
        if news_items:
            for item in news_items:
                with st.container(border=True):
                    # ì œëª© í´ë¦­ ì‹œ ë§í¬ ì´ë™
                    st.markdown(f"##### [{item['title']}]({item['link']})")
                    
                    # ë‚ ì§œì™€ ì¶œì²˜ í‘œì‹œ
                    try:
                        parsed_date = datetime.datetime.strptime(item['published'], "%a, %d %b %Y %H:%M:%S %Z")
                        date_str = parsed_date.strftime("%mì›” %dì¼ %H:%M")
                    except:
                        date_str = "ìµœê·¼"
                        
                    st.caption(f"ğŸ•’ {date_str} | ğŸ—ï¸ {item['source']}")
        else:
            st.warning("ì§€ê¸ˆì€ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            
    except Exception as e:
        st.error(f"ë‰´ìŠ¤ ë¡œë”© ì‹¤íŒ¨: {e}")
