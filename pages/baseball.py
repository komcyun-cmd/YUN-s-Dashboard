import streamlit as st
import feedparser
import google.generativeai as genai
import datetime
import json
import ast
import re

# ------------------------------------------------------------------
# [1] ì„¤ì •
# ------------------------------------------------------------------
st.set_page_config(page_title="KBO í”„ë¡œì•¼êµ¬ ë¸Œë¦¬í•‘", page_icon="âš¾", layout="centered")

if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])

model = genai.GenerativeModel('gemini-flash-latest')

st.title("âš¾ KBO í”„ë¡œì•¼êµ¬ Daily")
st.caption(f"AI í¸ì§‘êµ­ì¥ì´ ì—„ì„ í•œ ì˜¤ëŠ˜({datetime.date.today().strftime('%mì›” %dì¼')})ì˜ í•µì‹¬ ë‰´ìŠ¤ì…ë‹ˆë‹¤.")

# ------------------------------------------------------------------
# [2] ê¸°ëŠ¥ í•¨ìˆ˜
# ------------------------------------------------------------------
def get_raw_news():
    """RSSì—ì„œ ì›ë³¸ ë‰´ìŠ¤ 30ê°œë¥¼ ê¸ì–´ì˜µë‹ˆë‹¤."""
    # ê²€ìƒ‰ì–´ë¥¼ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ë³€ê²½
    rss_url = "https://news.google.com/rss/search?q=KBO+í”„ë¡œì•¼êµ¬+ê²½ê¸°+ê²°ê³¼+íŠ¸ë ˆì´ë“œ&hl=ko&gl=KR&ceid=KR:ko"
    feed = feedparser.parse(rss_url)
    
    news_pool = []
    for i, entry in enumerate(feed.entries[:30]): # 30ê°œë‚˜ ê°€ì ¸ì™€ì„œ AIì—ê²Œ íŒë‹¨ì‹œí‚´
        news_pool.append({
            "id": i,
            "title": entry.title,
            "link": entry.link,
            "published": entry.published,
            "source": entry.source.title if 'source' in entry else "ë‰´ìŠ¤"
        })
    return news_pool

def curate_news_with_ai(news_pool):
    """Geminiê°€ ë‰´ìŠ¤ ì œëª©ì„ ë³´ê³  ì¤‘ë³µì„ ì œê±°í•˜ê³  ì¤‘ìš” ê¸°ì‚¬ë§Œ ë½‘ìŠµë‹ˆë‹¤."""
    
    # AIì—ê²Œ ë³´ë‚¼ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ (IDì™€ ì œëª©ë§Œ)
    candidates = "\n".join([f"{item['id']}: {item['title']}" for item in news_pool])
    
    prompt = f"""
    ë‹¹ì‹ ì€ ê¹Œë‹¤ë¡œìš´ 'í”„ë¡œì•¼êµ¬ ë‰´ìŠ¤ í¸ì§‘ì¥'ì…ë‹ˆë‹¤. 
    ì•„ë˜ ë‰´ìŠ¤ ëª©ë¡(ID: ì œëª©)ì„ ë³´ê³ , ê°€ì¥ ì¤‘ìš”í•œ ê¸°ì‚¬ 5~7ê°œë¥¼ ì—„ì„ í•˜ì„¸ìš”.

    [ëª©ë¡]
    {candidates}

    [ì„ ë³„ ì›ì¹™]
    1. **ì¤‘ë³µ ì œê±° í•„ìˆ˜:** ê°™ì€ ì£¼ì œ(ì˜ˆ: ì»´íˆ¬ìŠ¤ ê²Œì„ ì¶œì‹œ, íŠ¹ì • ê²½ê¸° ê²°ê³¼)ì˜ ê¸°ì‚¬ê°€ ì—¬ëŸ¬ ê°œë©´ ê·¸ ì¤‘ ê°€ì¥ ì œëª©ì´ ê¹”ë”í•œ ê²ƒ **í•˜ë‚˜ë§Œ** ì„ íƒí•˜ì„¸ìš”.
    2. **ê´‘ê³ /ë³´ë„ìë£Œ í•„í„°ë§:** 'ì‚¬ì „ ì˜ˆì•½', 'ê²Œì„ ì¶œì‹œ', 'ì´ë²¤íŠ¸' ê°™ì€ í™ë³´ì„± ê¸°ì‚¬ëŠ” ê°€ê¸‰ì  ì œì™¸í•˜ê³ , ê²½ê¸° ê²°ê³¼, ì„ ìˆ˜ ì˜ì…, ë¶€ìƒ ë“± **'ì§„ì§œ ì•¼êµ¬ ë‰´ìŠ¤'**ë¥¼ ìš°ì„ í•˜ì„¸ìš”.
    3. **ë‹¤ì–‘ì„±:** íŠ¹ì • íŒ€ ì´ì•¼ê¸°ë§Œ í•˜ì§€ ë§ê³  ë‹¤ì–‘í•œ ì´ìŠˆë¥¼ ì„ìœ¼ì„¸ìš”.

    [ì¶œë ¥ í˜•ì‹]
    ì„ íƒí•œ ê¸°ì‚¬ì˜ ID ë¦¬ìŠ¤íŠ¸ë§Œ JSONìœ¼ë¡œ ì£¼ì„¸ìš”.
    ì˜ˆì‹œ: [0, 5, 12, 15, 22]
    """
    
    try:
        response = model.generate_content(prompt)
        text = response.text
        
        # ìˆ«ì ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ (ì •ê·œì‹ ì‚¬ìš©)
        match = re.search(r'\[.*\]', text, re.DOTALL)
        if match:
            selected_ids = json.loads(match.group())
            # ì„ íƒëœ IDì— í•´ë‹¹í•˜ëŠ” ë‰´ìŠ¤ë§Œ í•„í„°ë§
            final_list = [news for news in news_pool if news['id'] in selected_ids]
            return final_list
        else:
            return news_pool[:5] # ì‹¤íŒ¨í•˜ë©´ ê·¸ëƒ¥ ì• 5ê°œ ë¦¬í„´
    except:
        return news_pool[:5]

# ------------------------------------------------------------------
# [3] í™”ë©´ êµ¬ì„±
# ------------------------------------------------------------------

# ìƒë‹¨: í€µ ë§í¬ (HTML ë°©ì‹ - ì˜¤ë¥˜ ì—†ìŒ)
st.info("ğŸ‘‡ ê²½ê¸° ì¼ì • ë° í•˜ì´ë¼ì´íŠ¸ëŠ” ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ í™•ì¸í•˜ì„¸ìš”!")

st.markdown("""
<style>
    .kbo-btn {
        display: inline-block;
        width: 32%;
        padding: 10px 0;
        text-align: center;
        background-color: #f0f2f6;
        border-radius: 8px;
        text-decoration: none;
        color: #333;
        font-weight: bold;
        font-size: 0.9em;
        border: 1px solid #ddd;
    }
    .kbo-btn:hover { background-color: #e0e2e6; color: #007bff; }
</style>
<div style="display:flex; justify-content:space-between;">
    <a href="https://sports.news.naver.com/kbaseball/schedule/index.nhn" target="_blank" class="kbo-btn">ğŸ“… ê²½ê¸° ì¼ì •/ê²°ê³¼</a>
    <a href="https://sports.news.naver.com/kbaseball/record/index.nhn" target="_blank" class="kbo-btn">ğŸ† ì‹¤ì‹œê°„ ìˆœìœ„</a>
    <a href="https://www.youtube.com/results?search_query=KBO+í•˜ì´ë¼ì´íŠ¸+ì˜¤ëŠ˜" target="_blank" class="kbo-btn">ğŸ“º í•˜ì´ë¼ì´íŠ¸</a>
</div>
""", unsafe_allow_html=True)

st.divider()

# ë©”ì¸: AI ë‰´ìŠ¤ ë¸Œë¦¬í•‘
col_head, col_btn = st.columns([4, 1])
with col_head:
    st.subheader("ğŸ“° AI íë ˆì´ì…˜ ë‰´ìŠ¤")
with col_btn:
    if st.button("ìƒˆë¡œê³ ì¹¨ ğŸ”„"):
        st.rerun()

# ë¡œë”© ì¤‘ í‘œì‹œ
with st.spinner("AI í¸ì§‘ì¥ì´ 30ê°œì˜ ê¸°ì‚¬ë¥¼ ì½ê³  'ì§„ì§œ ë‰´ìŠ¤'ë§Œ ê³¨ë¼ë‚´ëŠ” ì¤‘ì…ë‹ˆë‹¤... ğŸ¤–"):
    try:
        # 1. ì›ë³¸ 30ê°œ ê°€ì ¸ì˜¤ê¸°
        raw_news = get_raw_news()
        
        if raw_news:
            # 2. AIê°€ ì„ ë³„í•˜ê¸°
            curated_news = curate_news_with_ai(raw_news)
            
            if curated_news:
                for item in curated_news:
                    with st.container(border=True):
                        st.markdown(f"##### [{item['title']}]({item['link']})")
                        
                        # ë‚ ì§œ í¬ë§·íŒ…
                        try:
                            parsed_date = datetime.datetime.strptime(item['published'], "%a, %d %b %Y %H:%M:%S %Z")
                            date_str = parsed_date.strftime("%mì›” %dì¼ %H:%M")
                        except:
                            date_str = "ì˜¤ëŠ˜"
                        
                        st.caption(f"ğŸ—ï¸ {item['source']} | ğŸ•’ {date_str}")
            else:
                st.info("AIê°€ ì„ ë³„í•  ë‰´ìŠ¤ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        else:
            st.warning("ë‰´ìŠ¤ í”¼ë“œë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        st.error(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
