import streamlit as st
import feedparser
import google.generativeai as genai
from youtube_transcript_api import YouTubeTranscriptApi
import datetime
import time

# ------------------------------------------------------------------
# [1] ì„¤ì • & ì±„ë„ ID (ì§í†µ ì£¼ì†Œ)
# ------------------------------------------------------------------
st.set_page_config(page_title="ì•¼êµ¬ ì§ê´€ ìƒí™©ì‹¤ (Real-time)", page_icon="âš¾", layout="wide")

if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])

model = genai.GenerativeModel('gemini-flash-latest')

# ìœ íŠœë¸Œ ì±„ë„ ID (ë¶ˆë³€ì˜ ê³ ìœ  ì£¼ì†Œ)
CHANNELS = {
    "KIA": {
        "name": "ğŸ¯ KIA íƒ€ì´ê±°ì¦ˆ (ê°¸í‹°ë¹„)",
        "rss_url": "https://www.youtube.com/feeds/videos.xml?channel_id=UCKp8knO8a6tSI1oaLjfd9XA", 
        "color": "#E30613"
    },
    "Hanwha": {
        "name": "ğŸ¦… í•œí™” ì´ê¸€ìŠ¤ (Eagles TV)",
        # í•œí™” ê³µì‹ ì±„ë„ ID (ê²€ì¦ë¨)
        "rss_url": "https://www.youtube.com/feeds/videos.xml?channel_id=UCdn4s7gPq7VDFirK40NqaSg",
        "color": "#F37321"
    }
}

# ì»¤ë®¤ë‹ˆí‹° RSS (ë””ì‹œì¸ì‚¬ì´ë“œ - ê°€ì¥ ë¹ ë¦„)
COMMUNITIES = {
    "KIA": "https://gall.dcinside.com/rss/lists/?id=tigers_new",
    "Hanwha": "https://gall.dcinside.com/rss/lists/?id=hanwhaeagles_new"
}

# ------------------------------------------------------------------
# [2] í•µì‹¬ ê¸°ëŠ¥: ë¬´ì¡°ê±´ ê°€ì ¸ì˜¤ê¸°
# ------------------------------------------------------------------
def get_latest_youtube_summaries(team_code, limit=2):
    """RSSë¥¼ í†µí•´ ìµœì‹  ì˜ìƒ 2ê°œë¥¼ ë¬´ì¡°ê±´ ê°€ì ¸ì™€ ìš”ì•½í•©ë‹ˆë‹¤."""
    channel = CHANNELS[team_code]
    feed = feedparser.parse(channel["rss_url"])
    
    results = []
    
    # ì˜ìƒì´ ì—†ê±°ë‚˜ ì—ëŸ¬ì¼ ê²½ìš°
    if not feed.entries:
        return [{"title": "ìµœì‹  ì˜ìƒì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "summary": "ì±„ë„ ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.", "url": ""}]

    # ìµœì‹ ìˆœ nê°œ ë°˜ë³µ
    for entry in feed.entries[:limit]:
        vid_id = entry.yt_videoid
        title = entry.title
        url = entry.link
        published = entry.published_parsed
        pub_date = datetime.datetime.fromtimestamp(time.mktime(published)).strftime('%Y-%m-%d')

        # ìë§‰ ì¶”ì¶œ ë° ìš”ì•½
        transcript_text = ""
        try:
            # í•œêµ­ì–´ ìë§‰ ì‹œë„
            t_list = YouTubeTranscriptApi.get_transcript(vid_id, languages=['ko'])
            for t in t_list: transcript_text += t['text'] + " "
        except:
            transcript_text = "(ìë§‰ ì—†ìŒ) ì˜ìƒ ì„¤ëª…ì´ë‚˜ ì œëª©ì„ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤."

        # AI ìš”ì•½ ìš”ì²­
        prompt = f"""
        ì´ ì•¼êµ¬ ì˜ìƒì˜ ë‚´ìš©ì„ 3ì¤„ë¡œ ìš”ì•½í•´.
        ì œëª©: {title}
        ìë§‰: {transcript_text[:3000]}
        
        [ì¡°ê±´]
        1. ê²½ê¸° ë‚´ìš©ì´ë©´ 'ëª‡ ëŒ€ ëª‡' ìŠ¹íŒ¨ì™€ í•µì‹¬ í™œì•½ ì„ ìˆ˜ë¥¼ ëª…ì‹œí•´.
        2. ì¸í„°ë·°ë©´ ì£¼ìš” ë°œì–¸ì„ ìš”ì•½í•´.
        3. íŒ¬ë“¤ì´ ì¢‹ì•„í•  ë§Œí•œ í¬ì¸íŠ¸(ê´€ì „ í¬ì¸íŠ¸)ë¥¼ í•œ ì¤„ ì¶”ê°€í•´.
        """
        try:
            summary = model.generate_content(prompt).text
        except:
            summary = "AI ìš”ì•½ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

        results.append({
            "title": title,
            "date": pub_date,
            "url": url,
            "summary": summary
        })
        
    return results

def get_community_issues(team_code, limit=10):
    """ì»¤ë®¤ë‹ˆí‹° RSSì—ì„œ ìµœì‹ ê¸€ nê°œë¥¼ ê¸ì–´ì™€ì„œ 'ì´ìŠˆ'ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    rss_url = COMMUNITIES[team_code]
    feed = feedparser.parse(rss_url)
    
    if not feed.entries:
        return "ì»¤ë®¤ë‹ˆí‹° ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
    # ìµœì‹  ê¸€ ì œëª©ë“¤ë§Œ ëª¨ìœ¼ê¸°
    titles = [f"- {entry.title}" for entry in feed.entries[:limit]]
    titles_text = "\n".join(titles)
    
    # AIì—ê²Œ ì´ìŠˆ ê·¸ë£¹í™” ìš”ì²­
    prompt = f"""
    ì•„ë˜ëŠ” ì‹¤ì‹œê°„ ì•¼êµ¬ íŒ¬ ì»¤ë®¤ë‹ˆí‹°(ë””ì‹œì¸ì‚¬ì´ë“œ)ì˜ ìµœì‹  ê¸€ ì œëª©ë“¤ì´ë‹¤.
    ì´ê²ƒë“¤ì„ ë¶„ì„í•´ì„œ 'ì§€ê¸ˆ ê°€ì¥ í•«í•œ ì´ìŠˆ' 3ê°€ì§€ë¥¼ ìš”ì•½í•´.
    
    [ìµœì‹  ê¸€ ì œëª© ëª©ë¡]
    {titles_text}
    
    [ì¶œë ¥ ì–‘ì‹]
    1. ğŸ”¥ **(ì´ìŠˆ 1)**: (ì„¤ëª…)
    2. ğŸ—£ï¸ **(ì´ìŠˆ 2)**: (ì„¤ëª…)
    3. â“ **(ì´ìŠˆ 3)**: (ì„¤ëª…)
    """
    try:
        return model.generate_content(prompt).text
    except:
        return "ì´ìŠˆ ë¶„ì„ ì‹¤íŒ¨"

# ------------------------------------------------------------------
# [3] í™”ë©´ êµ¬ì„±
# ------------------------------------------------------------------
st.title("âš¾ ì•¼êµ¬ ì§ê´€ ìƒí™©ì‹¤ (Direct Feed)")
st.caption("ê²€ìƒ‰ ì—”ì§„ì„ ê±°ì¹˜ì§€ ì•Šê³ , êµ¬ë‹¨ ì±„ë„ê³¼ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ì§ì ‘ ë°ì´í„°ë¥¼ ê½‚ì•„ì¤ë‹ˆë‹¤.")

tab1, tab2 = st.tabs(["ğŸ¯ ê¸°ì•„ íƒ€ì´ê±°ì¦ˆ", "ğŸ¦… í•œí™” ì´ê¸€ìŠ¤"])

# === [íƒ­ 1] ê¸°ì•„ ===
with tab1:
    st.header(f"{CHANNELS['KIA']['name']}")
    
    col1, col2 = st.columns([1.5, 1])
    
    with col1:
        st.subheader("ğŸ“º ìµœì‹  ê³µì‹ ì˜ìƒ (2ê°œ)")
        if st.button("ê¸°ì•„ ì˜ìƒ ê°€ì ¸ì˜¤ê¸° âš¡", key="btn_kia_yt"):
            with st.spinner("ì±„ë„ í”¼ë“œ ìŠ¤ìº” ì¤‘..."):
                videos = get_latest_youtube_summaries("KIA", 2)
                for v in videos:
                    st.markdown(f"### [{v['title']}]({v['url']})")
                    st.caption(f"ğŸ“… ì—…ë¡œë“œ: {v['date']}")
                    st.video(v['url'])
                    st.info(v['summary'])
                    st.divider()

    with col2:
        st.subheader("ğŸ”¥ ì‹¤ì‹œê°„ ì»¤ë®¤ë‹ˆí‹° ì´ìŠˆ")
        st.caption("ë””ì‹œì¸ì‚¬ì´ë“œ ê¸°ì•„ ê°¤ëŸ¬ë¦¬ ì‹¤ì‹œê°„ ë¶„ì„")
        if st.button("ê¸°ì•„ ë¯¼ì‹¬ í™•ì¸ âš¡", key="btn_kia_comm"):
            with st.spinner("ê°¤ëŸ¬ë¦¬ ê¸€ ì½ëŠ” ì¤‘..."):
                issues = get_community_issues("KIA", 15)
                st.markdown(issues)
                st.link_button("ê°¤ëŸ¬ë¦¬ ë°”ë¡œê°€ê¸°", "https://gall.dcinside.com/tigers_new")

# === [íƒ­ 2] í•œí™” ===
with tab2:
    st.header(f"{CHANNELS['Hanwha']['name']}")
    
    col1, col2 = st.columns([1.5, 1])
    
    with col1:
        st.subheader("ğŸ“º ìµœì‹  ê³µì‹ ì˜ìƒ (2ê°œ)")
        if st.button("í•œí™” ì˜ìƒ ê°€ì ¸ì˜¤ê¸° âš¡", key="btn_hanwha_yt"):
            with st.spinner("ì±„ë„ í”¼ë“œ ìŠ¤ìº” ì¤‘..."):
                videos = get_latest_youtube_summaries("Hanwha", 2)
                for v in videos:
                    st.markdown(f"### [{v['title']}]({v['url']})")
                    st.caption(f"ğŸ“… ì—…ë¡œë“œ: {v['date']}")
                    st.video(v['url'])
                    st.info(v['summary'])
                    st.divider()

    with col2:
        st.subheader("ğŸ”¥ ì‹¤ì‹œê°„ ì»¤ë®¤ë‹ˆí‹° ì´ìŠˆ")
        st.caption("ë””ì‹œì¸ì‚¬ì´ë“œ í•œí™” ê°¤ëŸ¬ë¦¬ ì‹¤ì‹œê°„ ë¶„ì„")
        if st.button("í•œí™” ë¯¼ì‹¬ í™•ì¸ âš¡", key="btn_hanwha_comm"):
            with st.spinner("ê°¤ëŸ¬ë¦¬ ê¸€ ì½ëŠ” ì¤‘..."):
                issues = get_community_issues("Hanwha", 15)
                st.markdown(issues)
                st.link_button("ê°¤ëŸ¬ë¦¬ ë°”ë¡œê°€ê¸°", "https://gall.dcinside.com/hanwhaeagles_new")

# ------------------------------------------------------------------
# [4] ìë™ ê°±ì‹  ì•Œë¦¼
# ------------------------------------------------------------------
st.sidebar.info("ğŸ’¡ ì´ ì•±ì€ RSS í”¼ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ **ë¬´ì¡°ê±´ ìµœì‹  ë°ì´í„°**ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.")
