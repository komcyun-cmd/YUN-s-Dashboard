import streamlit as st
import google.generativeai as genai
from duckduckgo_search import DDGS
from youtube_transcript_api import YouTubeTranscriptApi
from urllib.parse import urlparse, parse_qs
import datetime

# ------------------------------------------------------------------
# [1] ì„¤ì •
# ------------------------------------------------------------------
st.set_page_config(page_title="ìµœê°• ì•¼êµ¬ ë¹„ì„œ (Live)", page_icon="âš¾", layout="wide")

if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])

model = genai.GenerativeModel('gemini-flash-latest')

# ------------------------------------------------------------------
# [2] ê²€ìƒ‰ ë° í¬ë¡¤ë§ í•¨ìˆ˜ë“¤ (ìµœì‹ ì„± ê°•í™”)
# ------------------------------------------------------------------

def search_web_fresh(query, max_results=3, time_limit='d'):
    """
    DuckDuckGo ê²€ìƒ‰ (ì‹œê°„ ì œí•œ ì˜µì…˜ ì¶”ê°€)
    time_limit: 'd' (í•˜ë£¨), 'w' (ì¼ì£¼ì¼), 'm' (í•œë‹¬)
    """
    results = []
    try:
        with DDGS() as ddgs:
            # timelimit='d'ë¥¼ í†µí•´ ì§€ë‚œ 24ì‹œê°„ ë‚´ ê¸€ë§Œ ê°€ì ¸ì˜´
            gen = ddgs.text(query, max_results=max_results, timelimit=time_limit)
            results = list(gen)
    except Exception as e:
        # st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}") # ì‚¬ìš©ìì—ê²Œ ì—ëŸ¬ ë³´ì—¬ì£¼ì§€ ì•ŠìŒ
        pass
    return results

def get_video_id(url):
    """ìœ íŠœë¸Œ URLì—ì„œ ID ì¶”ì¶œ"""
    if not url: return None
    try:
        query = urlparse(url)
        if query.hostname == 'youtu.be': return query.path[1:]
        if query.hostname in ('www.youtube.com', 'youtube.com'):
            if query.path == '/watch': return parse_qs(query.query)['v'][0]
            if query.path[:7] == '/embed/': return query.path.split('/')[2]
            if query.path[:3] == '/v/': return query.path.split('/')[2]
    except:
        return None
    return None

def get_latest_youtube_summary(team_name):
    """íŒ€ì˜ ìµœì‹  ì˜ìƒ ê²€ìƒ‰ (ì¼ì£¼ì¼ ë‚´) ë° ìš”ì•½ ì‹œë„"""
    # 1. ìµœì‹  ì˜ìƒ ê²€ìƒ‰ (timelimit='w' : ìµœê·¼ ì¼ì£¼ì¼)
    search_query = f"site:youtube.com {team_name} ê³µì‹ í•˜ì´ë¼ì´íŠ¸"
    results = search_web_fresh(search_query, max_results=1, time_limit='w')
    
    if not results:
        return None, None, "ìµœê·¼ 1ì£¼ì¼ ë‚´ ì˜¬ë¼ì˜¨ ê³µì‹ ì˜ìƒì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
    video_title = results[0]['title']
    video_url = results[0]['href']
    video_desc = results[0]['body']
    video_id = get_video_id(video_url)
    
    # 2. ìë§‰ ì¶”ì¶œ ì‹œë„
    transcript_text = ""
    has_transcript = False
    
    if video_id:
        try:
            # í•œêµ­ì–´ ìë§‰ ìš°ì„  ì‹œë„
            transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['ko'])
            for entry in transcript_list:
                transcript_text += entry['text'] + " "
            has_transcript = True
        except:
            # ìë§‰ì´ ì—†ìœ¼ë©´ ì œëª©ê³¼ ê²€ìƒ‰ëœ ì„¤ëª…(body)ë§Œ ì‚¬ìš©
            transcript_text = f"ìë§‰ ì—†ìŒ. ì œëª©: {video_title}, ì„¤ëª…: {video_desc}"
            has_transcript = False

    # 3. AI ìš”ì•½
    prompt = f"""
    ì•„ë˜ ìœ íŠœë¸Œ ì˜ìƒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìš”ì•½í•´ì¤˜.
    ìë§‰ì´ ì—†ë‹¤ë©´ ì œëª©ê³¼ ì„¤ëª…ì„ ë°”íƒ•ìœ¼ë¡œ ì¶”ë¡ í•´.
    
    [ì˜ìƒ ì •ë³´]
    - íŒ€: {team_name}
    - ì œëª©: {video_title}
    - ìë§‰/ë‚´ìš©: {transcript_text[:3000]}
    
    [ìš”ì²­ì‚¬í•­]
    1. ì´ ì˜ìƒì´ ì–¸ì œ/ëˆ„êµ¬ì™€ì˜ ê²½ê¸°ì¸ì§€ íŒŒì•…í•´ì¤˜. (ì •ë³´ê°€ ì—†ìœ¼ë©´ 'ì•Œ ìˆ˜ ì—†ìŒ' í‘œê¸°)
    2. 3ì¤„ ìš”ì•½í•´ì¤˜.
    3. {'(ìë§‰ì´ ì—†ì–´ ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŒ)' if not has_transcript else ''}
    """
    try:
        summary = model.generate_content(prompt).text
        return video_url, video_title, summary
    except Exception as e:
        return video_url, video_title, f"AI ìš”ì•½ ì‹¤íŒ¨: {e}"

# ------------------------------------------------------------------
# [3] í™”ë©´ êµ¬ì„±
# ------------------------------------------------------------------
st.title("âš¾ ìµœê°• ì•¼êµ¬ ë¹„ì„œ (Live)")
st.caption("ì§€ë‚œ 24ì‹œê°„ ì´ë‚´ì˜ ì‚´ì•„ìˆëŠ” ë°ì´í„°ë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.")

tab1, tab2, tab3 = st.tabs(["ğŸ”® ì˜¤ëŠ˜ ìŠ¹ë¶€ì˜ˆì¸¡", "ğŸ“º ìµœì‹  ìœ íŠœë¸Œ", "ğŸ”¥ ì‹¤ì‹œê°„ ì»¤ë®¤ë‹ˆí‹°"])

# === [íƒ­ 1] ìŠ¹ë¶€ ì˜ˆì¸¡ (ì˜¤ëŠ˜ ë°ì´í„° ê°•ì œ) ===
with tab1:
    today_str = datetime.date.today().strftime("%Y-%m-%d")
    st.header(f"ì˜¤ëŠ˜({today_str})ì˜ ìŠ¹ë¶€ ğŸ†")
    
    if st.button("ë¼ì¸ì—… í™•ì¸ & ìŠ¹ë¥  ë¶„ì„ ğŸš€", type="primary"):
        with st.spinner("ì˜¤ëŠ˜ì ê¸°ì‚¬ ê²€ìƒ‰ ì¤‘ (ì§€ë‚œ 24ì‹œê°„)..."):
            # 'd' ì˜µì…˜ìœ¼ë¡œ ì˜¤ëŠ˜ ê¸°ì‚¬ë§Œ ê²€ìƒ‰
            q1 = f"ê¸°ì•„ íƒ€ì´ê±°ì¦ˆ í•œí™” ì´ê¸€ìŠ¤ ì˜¤ëŠ˜ ì„ ë°œ ë¼ì¸ì—… {today_str}"
            q2 = f"ê¸°ì•„ í•œí™” ì˜¤ëŠ˜ ê²½ê¸° í”„ë¦¬ë·° {today_str}"
            
            # ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì§‘
            res1 = search_web_fresh(q1, 3, 'd')
            res2 = search_web_fresh(q2, 3, 'd')
            
            combined_text = ""
            for r in res1 + res2:
                combined_text += f"- ì œëª©: {r['title']}\n- ë‚´ìš©: {r['body']}\n"
            
            if not combined_text:
                st.warning("ì˜¤ëŠ˜ì ê´€ë ¨ ê¸°ì‚¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê²½ê¸°ê°€ ì—†ëŠ” ë‚ ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                # AI ë¶„ì„
                st.divider()
                prompt = f"""
                ë„ˆëŠ” ì•¼êµ¬ ì „ë¬¸ ë¶„ì„ê°€ë‹¤. ì•„ë˜ 'ì˜¤ëŠ˜ì ê²€ìƒ‰ ê²°ê³¼'ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„í•´ë¼.
                
                [ê²€ìƒ‰ëœ ìµœì‹  ê¸°ì‚¬/ì •ë³´]
                {combined_text}
                
                [ë¶„ì„ ìš”ì²­]
                1. ì˜¤ëŠ˜ ì„ ë°œ íˆ¬ìˆ˜ì™€ ì£¼ìš” íƒ€ì ë¼ì¸ì—…ì„ ì •ë¦¬í•´ë¼. (ì •ë³´ê°€ ì—†ìœ¼ë©´ 'í™•ì¸ë˜ì§€ ì•ŠìŒ'ì´ë¼ê³  ë§í•´)
                2. ì–‘ íŒ€ì˜ ìµœê·¼ ë¶„ìœ„ê¸°ì™€ íˆ¬ìˆ˜ ì „ë ¥ì„ ë¹„êµí•´ë¼.
                3. **ê¸°ì•„ ìŠ¹ë¦¬ í™•ë¥  vs í•œí™” ìŠ¹ë¦¬ í™•ë¥ **ì„ %ë¡œ ì˜ˆì¸¡í•˜ê³  ê·¸ ê·¼ê±°ë¥¼ ëŒ€ë¼.
                """
                try:
                    analysis = model.generate_content(prompt).text
                    st.markdown(analysis)
                    
                    with st.expander("ì°¸ê³ í•œ ìµœì‹  ê¸°ì‚¬"):
                        for r in res1 + res2:
                            st.markdown(f"- [{r['title']}]({r['href']})")
                except:
                    st.error("AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

# === [íƒ­ 2] ìœ íŠœë¸Œ (ì˜ˆì™¸ì²˜ë¦¬ ê°•í™”) ===
with tab2:
    st.header("ê³µì‹ ì±„ë„ ìµœì‹  ì—…ë°ì´íŠ¸ ğŸ¬")
    st.caption("ìµœê·¼ 1ì£¼ì¼ ë‚´ ì˜¬ë¼ì˜¨ ì˜ìƒì„ ì°¾ìŠµë‹ˆë‹¤.")
    
    c1, c2 = st.columns(2)
    
    with c1:
        st.subheader("ğŸ¯ ê°¸í‹°ë¹„ (KIA)")
        if st.button("ê°¸í‹°ë¹„ ì¡°íšŒ"):
            with st.spinner("ì˜ìƒ ì°¾ëŠ” ì¤‘..."):
                url, title, summary = get_latest_youtube_summary("ê¸°ì•„ íƒ€ì´ê±°ì¦ˆ ê°¸í‹°ë¹„")
                if url:
                    st.video(url)
                    st.markdown(f"**{title}**")
                    st.info(summary)
                else:
                    st.warning(summary) # ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥

    with c2:
        st.subheader("ğŸ¦… ì´ê¸€ìŠ¤TV (Hanwha)")
        if st.button("ì´ê¸€ìŠ¤TV ì¡°íšŒ"):
            with st.spinner("ì˜ìƒ ì°¾ëŠ” ì¤‘..."):
                url, title, summary = get_latest_youtube_summary("í•œí™” ì´ê¸€ìŠ¤ ì´ê¸€ìŠ¤TV")
                if url:
                    st.video(url)
                    st.markdown(f"**{title}**")
                    st.info(summary)
                else:
                    st.warning(summary)

# === [íƒ­ 3] ì»¤ë®¤ë‹ˆí‹° (ì‹œê°„ ì œí•œ 'd' ì ìš©) ===
with tab3:
    st.header("ì‹¤ì‹œê°„ íŒ¬ ë¯¼ì‹¬ (24ì‹œê°„ ì´ë‚´) ğŸ”¥")
    
    if st.button("ğŸ”¥ ì‹¤ì‹œê°„ ì´ìŠˆ ìŠ¤ìº”"):
        with st.spinner("í¨ì½”, ì— íŒ, ë””ì‹œ ë“± ì£¼ìš” ì»¤ë®¤ë‹ˆí‹° ìŠ¤ìº” ì¤‘..."):
            # ê²€ìƒ‰ì–´ì— 'ì˜¤ëŠ˜', 'ì‹¤ì‹œê°„' ë“±ì„ í¬í•¨í•˜ê³  timelimit='d' ì ìš©
            queries = [
                "ê¸°ì•„ íƒ€ì´ê±°ì¦ˆ í¨ì½” í¬í… ì˜¤ëŠ˜",
                "í•œí™” ì´ê¸€ìŠ¤ ê°¤ëŸ¬ë¦¬ ê°œë…ê¸€ ì˜¤ëŠ˜",
                "ì— íŒ í•œêµ­ì•¼êµ¬ ì˜¤ëŠ˜ ê²½ê¸° ë°˜ì‘",
                "ì•¼êµ¬ë¶€ì¥ í¬ë³´ í•µì¸ì‹¸ ì˜¤ëŠ˜"
            ]
            
            raw_data = ""
            valid_sources = []
            
            for q in queries:
                # timelimit='d' (Day) í•µì‹¬!
                results = search_web_fresh(q, max_results=2, time_limit='d')
                for r in results:
                    raw_data += f"[{r['title']}] - {r['body']}\n"
                    valid_sources.append(r)
            
            if not raw_data:
                st.warning("ìµœê·¼ 24ì‹œê°„ ë‚´ í™”ì œê°€ ëœ ê¸€ì„ ì°¾ê¸° ì–´ë µìŠµë‹ˆë‹¤.")
            else:
                prompt = f"""
                ì•„ë˜ëŠ” 'ì˜¤ëŠ˜' ì˜¬ë¼ì˜¨ ì•¼êµ¬ íŒ¬ ì»¤ë®¤ë‹ˆí‹° ê¸€ë“¤ì´ë‹¤.
                ì˜›ë‚  ì´ì•¼ê¸°ëŠ” ë¬´ì‹œí•˜ê³ , **ì§€ê¸ˆ ë‹¹ì¥** íŒ¬ë“¤ì´ ì´ì•¼ê¸°í•˜ëŠ” ì£¼ì œë¥¼ ë½‘ì•„ë¼.
                
                [ê²€ìƒ‰ ë°ì´í„°]
                {raw_data}
                
                [ì¶œë ¥]
                1. ğŸ¯ **ê¸°ì•„ íŒ¬ë“¤ ì£¼ìš” ë°˜ì‘ 3ê°€ì§€**
                2. ğŸ¦… **í•œí™” íŒ¬ë“¤ ì£¼ìš” ë°˜ì‘ 3ê°€ì§€**
                3. âš¡ **ì˜¤ëŠ˜ì˜ í•« ì´ìŠˆ** (íŠ¸ë ˆì´ë“œ, ë¶€ìƒ, ê²½ê¸° ê²°ê³¼ ë“±)
                """
                try:
                    summary = model.generate_content(prompt).text
                    st.markdown(summary)
                    
                    with st.expander("ì¶œì²˜ (ì§€ë‚œ 24ì‹œê°„ ê²Œì‹œë¬¼)"):
                        for s in valid_sources:
                            st.markdown(f"- [{s['title']}]({s['href']})")
                except:
                    st.error("ìš”ì•½ ì‹¤íŒ¨")
