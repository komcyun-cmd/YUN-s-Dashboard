import streamlit as st
import google.generativeai as genai
from duckduckgo_search import DDGS
from youtube_transcript_api import YouTubeTranscriptApi
from urllib.parse import urlparse, parse_qs
import datetime

# ------------------------------------------------------------------
# [1] ì„¤ì •
# ------------------------------------------------------------------
st.set_page_config(page_title="ìµœê°• ì•¼êµ¬ ë¹„ì„œ (KIA vs Hanwha)", page_icon="âš¾", layout="wide")

if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])

model = genai.GenerativeModel('gemini-flash-latest')

# ------------------------------------------------------------------
# [2] ê²€ìƒ‰ ë° í¬ë¡¤ë§ í•¨ìˆ˜ë“¤
# ------------------------------------------------------------------

def search_web(query, max_results=3):
    """DuckDuckGoë¥¼ í†µí•´ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    results = []
    try:
        with DDGS() as ddgs:
            # ì•ˆì „í•˜ê²Œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            gen = ddgs.text(query, max_results=max_results)
            results = list(gen)
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
    return results

def get_video_id(url):
    """ìœ íŠœë¸Œ URLì—ì„œ ID ì¶”ì¶œ"""
    query = urlparse(url)
    if query.hostname == 'youtu.be': return query.path[1:]
    if query.hostname in ('www.youtube.com', 'youtube.com'):
        if query.path == '/watch': return parse_qs(query.query)['v'][0]
        if query.path[:7] == '/embed/': return query.path.split('/')[2]
        if query.path[:3] == '/v/': return query.path.split('/')[2]
    return None

def get_latest_youtube_summary(team_name):
    """íŠ¹ì • íŒ€ì˜ ìµœì‹  ìœ íŠœë¸Œ ì˜ìƒì„ ê²€ìƒ‰í•˜ê³  ìš”ì•½í•©ë‹ˆë‹¤."""
    # 1. ìµœì‹  ì˜ìƒ ê²€ìƒ‰
    search_query = f"{team_name} ê³µì‹ ìœ íŠœë¸Œ ìµœì‹  í•˜ì´ë¼ì´íŠ¸"
    results = search_web(search_query, max_results=1)
    
    if not results:
        return None, "ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
    video_title = results[0]['title']
    video_url = results[0]['href']
    video_id = get_video_id(video_url)
    
    # 2. ìë§‰ ì¶”ì¶œ
    transcript_text = ""
    try:
        if video_id:
            transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['ko', 'en'])
            for entry in transcript_list:
                transcript_text += entry['text'] + " "
    except:
        transcript_text = "(ìë§‰ì´ ì—†ëŠ” ì˜ìƒì´ê±°ë‚˜ ì ‘ê·¼ ë¶ˆê°€ì…ë‹ˆë‹¤. ì œëª©ê³¼ ë§¥ë½ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.)"

    # 3. AI ìš”ì•½
    prompt = f"""
    ì•„ë˜ ìœ íŠœë¸Œ ì˜ìƒì— ëŒ€í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ 3ì¤„ ìš”ì•½ì„ í•´ì¤˜.
    íŒ€: {team_name}
    ì˜ìƒ ì œëª©: {video_title}
    ìë§‰ ë‚´ìš©: {transcript_text[:5000]}
    
    [í˜•ì‹]
    1. ğŸ¥ **ì œëª©**: (ì œëª©)
    2. ğŸ“ **í•µì‹¬ ë‚´ìš©**: (ë‚´ìš© ìš”ì•½)
    3. ğŸ‘€ **ê´€ì „ í¬ì¸íŠ¸**: (íŒ¬ë“¤ì´ ì£¼ëª©í•  ë¶€ë¶„)
    """
    try:
        summary = model.generate_content(prompt).text
        return video_url, summary
    except Exception as e:
        return video_url, f"AI ìš”ì•½ ì‹¤íŒ¨: {e}"

# ------------------------------------------------------------------
# [3] í™”ë©´ êµ¬ì„±
# ------------------------------------------------------------------
st.title("âš¾ ìµœê°• ì•¼êµ¬ ë¹„ì„œ (KIA & Hanwha)")
st.caption("ìŠ¹ë¶€ ì˜ˆì¸¡ë¶€í„° íŒ¬ ë°˜ì‘ê¹Œì§€, ë°ì´í„°ë¡œ ì¦ê¸°ëŠ” ì•¼êµ¬")

tab1, tab2, tab3 = st.tabs(["ğŸ”® ì˜¤ëŠ˜ ê²½ê¸° ìŠ¹ë¶€ì˜ˆì¸¡", "ğŸ“º ìœ íŠœë¸Œ ìµœì‹  ìš”ì•½", "ğŸ”¥ ì»¤ë®¤ë‹ˆí‹° ì´ìŠˆ"])

# === [íƒ­ 1] ìŠ¹ë¶€ ì˜ˆì¸¡ ===
with tab1:
    st.header("ì˜¤ëŠ˜ì˜ ìŠ¹ìëŠ”? ğŸ†")
    
    today = datetime.date.today().strftime("%Yë…„ %mì›” %dì¼")
    st.info(f"ğŸ“… ê¸°ì¤€ì¼: {today}")
    
    if st.button("ë¼ì¸ì—… ê²€ìƒ‰ ë° ìŠ¹ë¥  ë¶„ì„ ğŸš€", type="primary"):
        with st.spinner("ë„¤ì´ë²„ ìŠ¤í¬ì¸ ì™€ ê¸°ì‚¬ë“¤ì„ ë’¤ì ¸ì„œ ë¼ì¸ì—…ì„ ì°¾ëŠ” ì¤‘..."):
            # 1. ì •ë³´ ìˆ˜ì§‘
            lineup_query = f"{today} í”„ë¡œì•¼êµ¬ ê¸°ì•„ í•œí™” ì„ ë°œ ë¼ì¸ì—… ì˜ˆìƒ"
            pitcher_query = f"{today} í”„ë¡œì•¼êµ¬ ê¸°ì•„ í•œí™” ì„ ë°œ íˆ¬ìˆ˜ ì „ì "
            
            lineup_data = search_web(lineup_query, 3)
            pitcher_data = search_web(pitcher_query, 3)
            
            combined_info = f"[ë¼ì¸ì—… ì •ë³´]\n{lineup_data}\n\n[ì„ ë°œíˆ¬ìˆ˜ ì •ë³´]\n{pitcher_data}"
            
            # 2. AI ë¶„ì„
            st.markdown("---")
            prompt = f"""
            ë„ˆëŠ” 20ë…„ ê²½ë ¥ì˜ ë² í…Œë‘ ì•¼êµ¬ ë¶„ì„ê°€ë‹¤.
            ì˜¤ëŠ˜({today}) ê¸°ì•„ íƒ€ì´ê±°ì¦ˆì™€ í•œí™” ì´ê¸€ìŠ¤ì˜ ê²½ê¸°ê°€ ìˆë‹¤ê³  ê°€ì •í•˜ê³ (í˜¹ì€ ê²€ìƒ‰ëœ ì •ë³´ ë°”íƒ•ìœ¼ë¡œ),
            ì•„ë˜ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë¶„ì„í•´ì„œ ìŠ¹ë¦¬ í™•ë¥ ì„ ì˜ˆì¸¡í•´ë¼.
            
            [ìˆ˜ì§‘ëœ ì›¹ ì •ë³´]
            {combined_info}
            
            ë§Œì•½ ì •í™•í•œ ë¼ì¸ì—… ì •ë³´ê°€ ì—†ë‹¤ë©´, ìµœê·¼ íŒ€ ë¶„ìœ„ê¸°ì™€ ì¼ë°˜ì ì¸ ì£¼ì „ ì„ ìˆ˜ë¥¼ ê°€ì •í•´ì„œ ì‹œë®¬ë ˆì´ì…˜í•´ë¼.
            
            [ì¶œë ¥ ì–‘ì‹]
            ## ğŸ“Š AI ìŠ¹ë¶€ ì˜ˆì¸¡
            
            ### 1. âš”ï¸ ì„ ë°œ ë§¤ì¹˜ì—… í‰ê°€
            (íˆ¬ìˆ˜ ì´ë¦„ ì–¸ê¸‰í•˜ë©° ë¹„êµ)
            
            ### 2. âš¾ íƒ€ì„  ë° ë³€ìˆ˜
            (í•µì‹¬ íƒ€ì ì»¨ë””ì…˜ ë“±)
            
            ### 3. ğŸ“ˆ ìŠ¹ë¦¬ í™•ë¥ 
            * **ê¸°ì•„ ìŠ¹ë¦¬ í™•ë¥ **: OO%
            * **í•œí™” ìŠ¹ë¦¬ í™•ë¥ **: OO%
            
            ### 4. ğŸ—£ï¸ í•œì¤„ í‰
            (íŒ¬ì‹¬ì„ ìê·¹í•˜ëŠ” ë©˜íŠ¸)
            """
            try:
                analysis = model.generate_content(prompt).text
                st.markdown(analysis)
                
                # ê·¼ê±° ìë£Œ(ë§í¬) í‘œì‹œ
                with st.expander("ì°¸ê³ í•œ ì›¹ ë¬¸ì„œ ë³´ê¸°"):
                    for item in lineup_data + pitcher_data:
                        st.markdown(f"- [{item['title']}]({item['href']})")
                        
            except Exception as e:
                st.error("ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

# === [íƒ­ 2] ìœ íŠœë¸Œ ìš”ì•½ ===
with tab2:
    st.header("ê³µì‹ ìœ íŠœë¸Œ ìµœì‹  ì—…ë°ì´íŠ¸ ğŸ¬")
    
    col_kia, col_hanwha = st.columns(2)
    
    with col_kia:
        st.subheader("ğŸ¯ ê°¸í‹°ë¹„ (KIA)")
        if st.button("ê°¸í‹°ë¹„ ìš”ì•½í•˜ê¸°"):
            with st.spinner("ì˜ìƒ ì°¾ì•„ì˜¤ëŠ” ì¤‘..."):
                url, summary = get_latest_youtube_summary("ê¸°ì•„ íƒ€ì´ê±°ì¦ˆ ê°¸í‹°ë¹„")
                if url:
                    st.video(url)
                    st.info(summary)
                else:
                    st.error(summary)
                    
    with col_hanwha:
        st.subheader("ğŸ¦… ì´ê¸€ìŠ¤TV (Hanwha)")
        if st.button("ì´ê¸€ìŠ¤TV ìš”ì•½í•˜ê¸°"):
            with st.spinner("ì˜ìƒ ì°¾ì•„ì˜¤ëŠ” ì¤‘..."):
                url, summary = get_latest_youtube_summary("í•œí™” ì´ê¸€ìŠ¤ ì´ê¸€ìŠ¤TV")
                if url:
                    st.video(url)
                    st.info(summary)
                else:
                    st.error(summary)

# === [íƒ­ 3] ì»¤ë®¤ë‹ˆí‹° ì´ìŠˆ ===
with tab3:
    st.header("íŒ¬ ì»¤ë®¤ë‹ˆí‹° ë¯¼ì‹¬ ğŸ”¥")
    st.caption("í¨ì½”, ì— íŒ, ë””ì‹œì¸ì‚¬ì´ë“œ ë“±ì˜ ìµœì‹  ë°˜ì‘ì„ ëª¨ì•„ë´…ë‹ˆë‹¤.")
    
    if st.button("ğŸ”¥ ì‹¤ì‹œê°„ ì´ìŠˆ ìŠ¤ìº”"):
        with st.spinner("ì•¼êµ¬ íŒ¬ë“¤ì˜ í‚¤ë³´ë“œ ë°°í‹€ í˜„ì¥ì„ ì—¼íƒ ì¤‘..."):
            # ê²€ìƒ‰ì–´ ì„¤ì •
            queries = [
                "ê¸°ì•„ íƒ€ì´ê±°ì¦ˆ í¨ì½” í¬í…",
                "í•œí™” ì´ê¸€ìŠ¤ ê°¤ëŸ¬ë¦¬ ê°œë…ê¸€",
                "ì— íŒ í•œêµ­ì•¼êµ¬ íƒ€ì„ë¼ì¸",
                "ê¸°ì•„ í•œí™” ì˜¤ëŠ˜ ê²½ê¸° ë°˜ì‘"
            ]
            
            community_data = ""
            sources = []
            
            for q in queries:
                results = search_web(q, 2)
                for r in results:
                    community_data += f"- {r['title']}: {r['body']}\n"
                    sources.append(r)
            
            # AI ìš”ì•½
            prompt = f"""
            ì•„ë˜ëŠ” ì•¼êµ¬ íŒ¬ ì»¤ë®¤ë‹ˆí‹°ì˜ ìµœì‹  ê²€ìƒ‰ ê²°ê³¼ë‹¤.
            ê¸°ì•„(KIA)ì™€ í•œí™”(Hanwha) ê°ê°ì˜ ì£¼ìš” ì´ìŠˆ 5ê°€ì§€ì”©ì„ ìš”ì•½í•´ë¼.
            ìš•ì„¤ì´ë‚˜ ë¹„í•˜ ë°œì–¸ì€ ìˆœí™”í•˜ê³ , íŒ¬ë“¤ì˜ 'ì£¼ìš” ì—¬ë¡ 'ì´ ë¬´ì—‡ì¸ì§€ íŒŒì•…í•´ë¼.
            
            [ê²€ìƒ‰ ë°ì´í„°]
            {community_data}
            
            [ì¶œë ¥ ì–‘ì‹]
            ### ğŸ¯ ê¸°ì•„ íƒ€ì´ê±°ì¦ˆ ì´ìŠˆ Top 5
            1. 
            2. ...
            
            ### ğŸ¦… í•œí™” ì´ê¸€ìŠ¤ ì´ìŠˆ Top 5
            1.
            2. ...
            
            ### ğŸ’¡ 3ì¤„ ìš”ì•½ (ë¯¼ì‹¬ ì´í‰)
            """
            try:
                summary = model.generate_content(prompt).text
                st.markdown(summary)
                
                with st.expander("ì¶œì²˜ ì›ë¬¸ ë§í¬"):
                    for s in sources:
                        st.markdown(f"- [{s['title']}]({s['href']})")
            except Exception as e:
                st.error("ì´ìŠˆ ìš”ì•½ ì‹¤íŒ¨")
